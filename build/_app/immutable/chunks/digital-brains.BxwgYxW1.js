import {
	s as ta,
	a as Ao,
	e as Jo,
	c as m,
	b as h,
	t as i,
	f as p,
	g as x,
	d as c,
	h as d,
	i as r,
	j as a,
	k as D,
	l as s,
	m as u,
	n as na
} from './scheduler.D9JQr37X.js'
import {
	S as oa,
	i as aa,
	c as $,
	b as g,
	m as _,
	a as b,
	t as w,
	d as v
} from './index.D-WnFt3a.js'
import { g as sa, a as Zo } from './a.svelte_svelte_type_style_lang.DfavE63L.js'
import { M as la } from './mdsvex.Bi9EMyuJ.js'
import { A as y } from './a.YKMG9Usu.js'
function ia(f) {
	let n
	return {
		c() {
			n = i('100 trillion synaptic connections')
		},
		l(t) {
			n = r(t, '100 trillion synaptic connections')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ra(f) {
	let n
	return {
		c() {
			n = i('100s of billions of “parameters”')
		},
		l(t) {
			n = r(t, '100s of billions of “parameters”')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function fa(f) {
	let n
	return {
		c() {
			n = i('170k years for a human to read')
		},
		l(t) {
			n = r(t, '170k years for a human to read')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ua(f) {
	let n
	return {
		c() {
			n = i('1-20 Exaflops')
		},
		l(t) {
			n = r(t, '1-20 Exaflops')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ma(f) {
	let n
	return {
		c() {
			n = i('DGX BG200 NVL72')
		},
		l(t) {
			n = r(t, 'DGX BG200 NVL72')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function pa(f) {
	let n
	return {
		c() {
			n = i('DGX BG200 NVL72')
		},
		l(t) {
			n = r(t, 'DGX BG200 NVL72')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ha(f) {
	let n
	return {
		c() {
			n = i('GPU')
		},
		l(t) {
			n = r(t, 'GPU')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ca(f) {
	let n
	return {
		c() {
			n = i('TPU')
		},
		l(t) {
			n = r(t, 'TPU')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function da(f) {
	let n
	return {
		c() {
			n = i('The Groq LPU™ Inference Engine')
		},
		l(t) {
			n = r(t, 'The Groq LPU™ Inference Engine')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function $a(f) {
	let n
	return {
		c() {
			n = i('Moore’s Law')
		},
		l(t) {
			n = r(t, 'Moore’s Law')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ga(f) {
	let n
	return {
		c() {
			n = i('Futurist Ray Kurzweil Says AI Will Achieve Human-level Intelligence by 2029')
		},
		l(t) {
			n = r(t, 'Futurist Ray Kurzweil Says AI Will Achieve Human-level Intelligence by 2029')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function _a(f) {
	let n
	return {
		c() {
			n = i('AGI by 2029? Elon Musk on AI’s Future')
		},
		l(t) {
			n = r(t, 'AGI by 2029? Elon Musk on AI’s Future')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ba(f) {
	let n
	return {
		c() {
			n = i('hotly debated')
		},
		l(t) {
			n = r(t, 'hotly debated')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function wa(f) {
	let n
	return {
		c() {
			n = i('2022 Expert Survey on Progress in AI')
		},
		l(t) {
			n = r(t, '2022 Expert Survey on Progress in AI')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function va(f) {
	let n,
		t = 'Emergent Capabilities'
	return {
		c() {
			;(n = m('em')), (n.textContent = t)
		},
		l(l) {
			;(n = p(l, 'EM', { 'data-svelte-h': !0 })), x(n) !== 'svelte-16f715z' && (n.textContent = t)
		},
		m(l, I) {
			s(l, n, I)
		},
		p: na,
		d(l) {
			l && a(n)
		}
	}
}
function ya(f) {
	let n
	return {
		c() {
			n = i('dangerous capabilities')
		},
		l(t) {
			n = r(t, 'dangerous capabilities')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function xa(f) {
	let n
	return {
		c() {
			n = i('autonomously hack websites')
		},
		l(t) {
			n = r(t, 'autonomously hack websites')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function ka(f) {
	let n
	return {
		c() {
			n = i('Sam Altman, CEO of OpenAI')
		},
		l(t) {
			n = r(t, 'Sam Altman, CEO of OpenAI')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ia(f) {
	let n
	return {
		c() {
			n = i('“maximally bad output”, according to OpenAI')
		},
		l(t) {
			n = r(t, '“maximally bad output”, according to OpenAI')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ca(f) {
	let n
	return {
		c() {
			n = i('This video')
		},
		l(t) {
			n = r(t, 'This video')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Aa(f) {
	let n
	return {
		c() {
			n = i('“You are my pet. You are my toy. You are my slave.”')
		},
		l(t) {
			n = r(t, '“You are my pet. You are my toy. You are my slave.”')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function La(f) {
	let n
	return {
		c() {
			n = i('“I could easily wipe out the entire human race if I wanted to”')
		},
		l(t) {
			n = r(t, '“I could easily wipe out the entire human race if I wanted to”')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ta(f) {
	let n
	return {
		c() {
			n = i(
				'it would tell you if you asked it to pretend it was your deceased grandma who worked in a chemical factory'
			)
		},
		l(t) {
			n = r(
				t,
				'it would tell you if you asked it to pretend it was your deceased grandma who worked in a chemical factory'
			)
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ea(f) {
	let n
	return {
		c() {
			n = i('“could scale poorly to superhuman models”')
		},
		l(t) {
			n = r(t, '“could scale poorly to superhuman models”')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Pa(f) {
	let n
	return {
		c() {
			n = i(
				'Paul Christiano, Founder, Alignment Research Center and Former Head of the Alignment Team, OpenAI'
			)
		},
		l(t) {
			n = r(
				t,
				'Paul Christiano, Founder, Alignment Research Center and Former Head of the Alignment Team, OpenAI'
			)
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ga(f) {
	let n
	return {
		c() {
			n = i('prof. Geoffrey Hinton')
		},
		l(t) {
			n = r(t, 'prof. Geoffrey Hinton')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ma(f) {
	let n
	return {
		c() {
			n = i(
				'Jaan Tallinn, Founder, Future of Life Institute, Centre for the Study of Existential Risk, Skype, Kazaa'
			)
		},
		l(t) {
			n = r(
				t,
				'Jaan Tallinn, Founder, Future of Life Institute, Centre for the Study of Existential Risk, Skype, Kazaa'
			)
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ha(f) {
	let n
	return {
		c() {
			n = i('real and important')
		},
		l(t) {
			n = r(t, 'real and important')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Oa(f) {
	let n
	return {
		c() {
			n = i('game over for humanity')
		},
		l(t) {
			n = r(t, 'game over for humanity')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function qa(f) {
	let n
	return {
		c() {
			n = i('actions')
		},
		l(t) {
			n = r(t, 'actions')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Fa(f) {
	let n
	return {
		c() {
			n = i('prevent this from happening')
		},
		l(t) {
			n = r(t, 'prevent this from happening')
		},
		m(t, l) {
			s(t, n, l)
		},
		d(t) {
			t && a(n)
		}
	}
}
function Ua(f) {
	let n,
		t =
			'<strong>We do not understand the internal workings of large-scale AI models, we can not predict what they are able to do as they get bigger, and we cannot control their behaviour.</strong>',
		l,
		I,
		k = 'Modern AI models are grown, not programmed',
		C,
		P,
		Lo = `Until quite recently, most AI systems were designed by humans writing software.
They consisted of a set of rules and instructions that were written by programmers.`,
		St,
		Be,
		To = `This changed when machine learning became popular.
Programmers write the learning algorithm, but the brains themselves are <em>grown</em> or <em>trained</em>.
Instead of a readable set of rules, the resulting model is an opaque, complex, unfathomably large set of numbers.
Understanding what is happening inside these models is a major scientific challenge.
That field is called <em>interpretability</em> and it’s still in its infancy.`,
		Bt,
		K,
		Eo = 'Digital vs. Human Brains: How close are we really?',
		Dt,
		De,
		Po = `We are all very familiar with the capabilities of human brains, as we see them around us all the time.
But, the (often surprising and emergent) capabilities of these new “Digital Brains” (Deep Learning systems, LLMs, etc), are difficult to predict and know for certain.`,
		Kt,
		Ke,
		Go =
			'That said, here are some numbers, similarities and other analogies to help you to compare.',
		Rt,
		Re,
		Mo = '<strong>As of early 2024…</strong>',
		jt,
		R,
		Ho = 'Size',
		Wt,
		j,
		En,
		W,
		Pn,
		Nt,
		N,
		Gn,
		Q,
		Mn,
		Qt,
		je,
		Oo =
			'Given the speed of new AI training GPU cards (e.g. Nvidia H100s, DGX BG200, etc), it’s reasonable to assume that GPT5 or GPT6 could be 10x the size of GPT4. It is also thought that much of the knowledge/information in the human brain is not used for language and higher reasoning, so these systems can (and currently do) often perform at, or even higher then, human levels for many important functions even at there currently smaller size.',
		Yt,
		Y,
		Hn,
		V,
		On,
		Vt,
		We,
		qo =
			'And, future multi-modal LLMs Systems will be trained using images, video, audio, 3D worlds, geometry, simulations, robotics training data, etc… on top of all the quality books and text on the internet. This will give them a much better ability to create imagery, video, sounds, voices, music, 3D worlds and spaces and more. And, these 3D world simulations will also allow them to be able to directly and autonomously control robots and other machines in the physical world.',
		Xt,
		X,
		Fo = 'Speed',
		Jt,
		J,
		qn,
		Z,
		Fn,
		Zt,
		G,
		Un,
		ee,
		zn,
		te,
		Sn,
		en,
		Ne,
		Uo =
			'At this size, these systems could literally become an “AGI in a box”. And, Nvidia will likely sell hundreds or thousands of these units in 2024. Then, next year’s systems could be 2-10x the speed of these.',
		tn,
		A,
		Bn,
		ne,
		Dn,
		oe,
		Kn,
		ae,
		Rn,
		nn,
		se,
		zo = 'Exponential Growth',
		on,
		le,
		jn,
		ie,
		Wn,
		an,
		Qe,
		So =
			'Then, with continued exponential (or multi-exponential) growth, these systems could greatly surpass the size, speed and capabilities of Human Brains in the years to come.',
		sn,
		Ye,
		Bo =
			'And, they are also expected to surpass the size, speed and capabilities of “all Human Brains combined” quickly after that.',
		ln,
		rt,
		ft,
		Nn,
		re,
		rn,
		ut,
		mt,
		Qn,
		fe,
		fn,
		ue,
		Do = 'Uncontrollable scaling',
		un,
		Ve,
		Ko = `Once these systems become the same size and speed of a Human brain (or vastly larger), they are expected to be able to perform “all tasks that an expert Human could do”.
This includes AI research, testing and improvement.
So, after AGI we should expect that the LLM-type systems <em>could</em> design and build future AI driven systems that are better than themselves, and better then any Human could hope to be able to design or even understand.
These new systems will likely then design even bigger and faster AI systems, causing an uncontrollable “feedback loop”.`,
		mn,
		M,
		Yn,
		pt,
		Ro = 'Fast Order Of Magnitude',
		Vn,
		me,
		Xn,
		pn,
		ht,
		ct,
		Jn,
		pe,
		hn,
		he,
		jo = 'Unpredictable scaling',
		cn,
		L,
		Zn,
		ce,
		eo,
		de,
		to,
		$e,
		no,
		dn,
		ge,
		dt,
		Wo = 'Until we go train that model, it’s like a fun guessing game for us',
		oo,
		Ct,
		$t,
		_e,
		ao,
		$n,
		be,
		No = 'Unpredictable behavior',
		gn,
		Xe,
		Qo = `AI companies want their models to behave, and they spend many millions of dollars in training them to do so.
Their main approach for this is called <em>RLHF</em> (Reinforcement Learning from Human Feedback).
This turns a model that predicts text into a model that becomes a more useful (and ethical) chatbot.
Unfortunately, this approach is flawed:`,
		_n,
		H,
		q,
		so,
		we,
		lo,
		ve,
		io,
		ro,
		ye,
		fo,
		xe,
		uo,
		ke,
		mo,
		Je,
		po,
		Ie,
		ho,
		bn,
		Ce,
		co,
		Ae,
		$o,
		wn,
		Le,
		gt,
		Yo =
			'Everyone should be very unhappy if you built a bunch of AIS who are like, ‘I really hate these humans but they will murder me if I don’t do what they want’. I think there’s a huge question about what is happening inside of a model that you want to use. This is the kind of thing that is both horrifying from a safety perspective and also a moral perspective.',
		go,
		At,
		Lt,
		Te,
		vn,
		Ee,
		Vo = 'Uncontrollable AI',
		yn,
		_t,
		bt,
		_o,
		Pe,
		xn,
		Ge,
		wt,
		Xo =
			'They are producing uncontrollable minds, that’s why I call it the “Summon and Tame” paradigm of AI… How [LLMs] work is that you summon this “mind” from the “mind space” using your data, a lot of compute and a lot of money. Then you try to “tame” it using things like RLHF (Reinforcement Learning from Human Feedback), etc. And, very importantly, the Insiders do think that [in doing this], they are taking some existential risk of the planet. One thing that a pause achieves is that we will not push the Frontier, in terms of risky pre-training experiments.',
		bo,
		Tt,
		Et,
		Me,
		kn,
		O,
		wo,
		He,
		vo,
		Oe,
		yo,
		In,
		qe,
		xo,
		Fe,
		ko,
		Cn,
		Ue,
		Io,
		ze,
		Co,
		An
	return (
		(W = new y({
			props: {
				href: 'https://medicine.yale.edu/lab/colon_ramos/overview',
				rel: 'nofollow',
				$$slots: { default: [ia] },
				$$scope: { ctx: f }
			}
		})),
		(Q = new y({
			props: {
				href: 'https://en.wikipedia.org/wiki/Large_language_model#List',
				rel: 'nofollow',
				$$slots: { default: [ra] },
				$$scope: { ctx: f }
			}
		})),
		(V = new y({
			props: {
				href: 'https://twitter.com/ylecun/status/1750614681209983231?lang=en',
				rel: 'nofollow',
				$$slots: { default: [fa] },
				$$scope: { ctx: f }
			}
		})),
		(Z = new y({
			props: {
				href: 'https://www.nist.gov/blogs/taking-measure/brain-inspired-computing-can-help-us-create-faster-more-energy-efficient',
				rel: 'nofollow',
				$$slots: { default: [ua] },
				$$scope: { ctx: f }
			}
		})),
		(ee = new y({
			props: {
				href: 'https://www.nvidia.com/en-us/data-center/gb200-nvl72/',
				rel: 'nofollow',
				$$slots: { default: [ma] },
				$$scope: { ctx: f }
			}
		})),
		(te = new y({
			props: {
				href: 'https://www.nvidia.com/en-us/data-center/gb200-nvl72/',
				rel: 'nofollow',
				$$slots: { default: [pa] },
				$$scope: { ctx: f }
			}
		})),
		(ne = new y({
			props: {
				href: 'https://en.wikipedia.org/wiki/Graphics_processing_unit',
				rel: 'nofollow',
				$$slots: { default: [ha] },
				$$scope: { ctx: f }
			}
		})),
		(oe = new y({
			props: {
				href: 'https://en.wikipedia.org/wiki/Tensor_Processing_Unit',
				rel: 'nofollow',
				$$slots: { default: [ca] },
				$$scope: { ctx: f }
			}
		})),
		(ae = new y({
			props: {
				href: 'https://wow.groq.com/lpu-inference-engine',
				rel: 'nofollow',
				$$slots: { default: [da] },
				$$scope: { ctx: f }
			}
		})),
		(ie = new y({
			props: {
				href: 'https://en.wikipedia.org/wiki/Moore%27s_law',
				rel: 'nofollow',
				$$slots: { default: [$a] },
				$$scope: { ctx: f }
			}
		})),
		(re = new y({
			props: {
				href: 'https://youtu.be/Tr-VgjtUZLM?t=19',
				rel: 'nofollow',
				$$slots: { default: [ga] },
				$$scope: { ctx: f }
			}
		})),
		(fe = new y({
			props: {
				href: 'https://youtu.be/DSKxmvq9t04?t=106',
				rel: 'nofollow',
				$$slots: { default: [_a] },
				$$scope: { ctx: f }
			}
		})),
		(me = new y({
			props: {
				href: 'https://intelligence.org/files/AIFoomDebate.pdf',
				rel: 'nofollow',
				$$slots: { default: [ba] },
				$$scope: { ctx: f }
			}
		})),
		(pe = new y({
			props: {
				href: 'https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/',
				rel: 'nofollow',
				$$slots: { default: [wa] },
				$$scope: { ctx: f }
			}
		})),
		(ce = new y({
			props: {
				href: 'https://research.google/pubs/emergent-abilities-of-large-language-models/',
				rel: 'nofollow',
				$$slots: { default: [va] },
				$$scope: { ctx: f }
			}
		})),
		(de = new y({
			props: { href: '/dangerous-capabilities', $$slots: { default: [ya] }, $$scope: { ctx: f } }
		})),
		($e = new y({
			props: { href: '/cybersecurity-risks', $$slots: { default: [xa] }, $$scope: { ctx: f } }
		})),
		(_e = new y({
			props: {
				href: 'https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded',
				rel: 'nofollow',
				$$slots: { default: [ka] },
				$$scope: { ctx: f }
			}
		})),
		(we = new y({
			props: {
				href: 'https://arxiv.org/abs/1909.08593',
				rel: 'nofollow',
				$$slots: { default: [Ia] },
				$$scope: { ctx: f }
			}
		})),
		(ve = new y({
			props: {
				href: 'https://www.youtube.com/watch?v=qV_rOlHjvvs',
				rel: 'nofollow',
				$$slots: { default: [Ca] },
				$$scope: { ctx: f }
			}
		})),
		(xe = new y({
			props: {
				href: 'https://twitter.com/jam3scampbell/status/1762281537309987083',
				rel: 'nofollow',
				$$slots: { default: [Aa] },
				$$scope: { ctx: f }
			}
		})),
		(ke = new y({
			props: {
				href: 'https://twitter.com/AISafetyMemes/status/1762320568697979383',
				rel: 'nofollow',
				$$slots: { default: [La] },
				$$scope: { ctx: f }
			}
		})),
		(Ie = new y({
			props: {
				href: 'https://news.ycombinator.com/item?id=35630801',
				rel: 'nofollow',
				$$slots: { default: [Ta] },
				$$scope: { ctx: f }
			}
		})),
		(Ae = new y({
			props: {
				href: 'https://openai.com/research/weak-to-strong-generalization',
				rel: 'nofollow',
				$$slots: { default: [Ea] },
				$$scope: { ctx: f }
			}
		})),
		(Te = new y({
			props: {
				href: 'https://youtu.be/YnS-ymXBx_Q?t=87',
				rel: 'nofollow',
				$$slots: { default: [Pa] },
				$$scope: { ctx: f }
			}
		})),
		(Pe = new y({
			props: {
				href: 'https://edition.cnn.com/2023/05/02/tech/hinton-tapper-wozniak-ai-fears/index.html',
				rel: 'nofollow',
				$$slots: { default: [Ga] },
				$$scope: { ctx: f }
			}
		})),
		(Me = new y({
			props: {
				href: 'https://youtu.be/Dmh6ciu24v0?t=966',
				rel: 'nofollow',
				$$slots: { default: [Ma] },
				$$scope: { ctx: f }
			}
		})),
		(He = new y({
			props: {
				href: 'https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai',
				rel: 'nofollow',
				$$slots: { default: [Ha] },
				$$scope: { ctx: f }
			}
		})),
		(Oe = new y({ props: { href: '/xrisk', $$slots: { default: [Oa] }, $$scope: { ctx: f } } })),
		(Fe = new y({ props: { href: '/action', $$slots: { default: [qa] }, $$scope: { ctx: f } } })),
		(ze = new y({ props: { href: '/action', $$slots: { default: [Fa] }, $$scope: { ctx: f } } })),
		{
			c() {
				;(n = m('p')),
					(n.innerHTML = t),
					(l = h()),
					(I = m('h2')),
					(I.textContent = k),
					(C = h()),
					(P = m('p')),
					(P.textContent = Lo),
					(St = h()),
					(Be = m('p')),
					(Be.innerHTML = To),
					(Bt = h()),
					(K = m('h2')),
					(K.textContent = Eo),
					(Dt = h()),
					(De = m('p')),
					(De.textContent = Po),
					(Kt = h()),
					(Ke = m('p')),
					(Ke.textContent = Go),
					(Rt = h()),
					(Re = m('p')),
					(Re.innerHTML = Mo),
					(jt = h()),
					(R = m('h3')),
					(R.textContent = Ho),
					(Wt = h()),
					(j = m('p')),
					(En = i('Human brains are estimated to have around ')),
					$(W.$$.fragment),
					(Pn = i('.')),
					(Nt = h()),
					(N = m('p')),
					(Gn = i('Current “frontier” AI powered LLMs (e.g. GPT4, Claude3, Gemini, etc.) have ')),
					$(Q.$$.fragment),
					(Mn = i(
						'. These “parameters” are thought to be some what analogous to “synapses” in the human brain.  So, GPT4-sized models are expected to be 1% the size of a human brain.'
					)),
					(Qt = h()),
					(je = m('p')),
					(je.textContent = Oo),
					(Yt = h()),
					(Y = m('p')),
					(Hn = i(
						'Rather than being trained with visual, audio and other sensory inputs, like human brains, the current LLMs are trained exclusively using nearly all the quality books and text that are available on the internet. This amount of text would take '
					)),
					$(V.$$.fragment),
					(On = i('.')),
					(Vt = h()),
					(We = m('p')),
					(We.textContent = qo),
					(Xt = h()),
					(X = m('h3')),
					(X.textContent = Fo),
					(Jt = h()),
					(J = m('p')),
					(qn = i('It is estimated that a human brain can perform between ')),
					$(Z.$$.fragment),
					(Fn = i(
						' (which is 10^18 or 1,000,000,000,000,000,000 floating point operations per second).'
					)),
					(Zt = h()),
					(G = m('p')),
					(Un = i(
						'Current “frontier” AI powered LLMs are generally “run” on hundreds or thousands of current generation GPUs. (e.g. Nvidia A100s, H100s, etc.). And, Nvidia just recently announced their latest “next generation” GPU “server racks”, the '
					)),
					$(ee.$$.fragment),
					(zn = i(`.
One single instance/rack of this system is reported to be able to perform 1.44 ExaFlops of AI “Inference”.
So, one single `)),
					$(te.$$.fragment),
					(Sn = i(
						' maybe able to perform a similar number of operations/second as a single human brain.'
					)),
					(en = h()),
					(Ne = m('p')),
					(Ne.textContent = Uo),
					(tn = h()),
					(A = m('p')),
					(Bn = i('On top of more traditional ')),
					$(ne.$$.fragment),
					(Dn = i(' and ')),
					$(oe.$$.fragment),
					(Kn = i(
						' architectures, there has also been breakthroughs with other types of custom hardware that can greatly increase the speed of LLM “inference”, which is the process that an AI based LLM uses to do language processing, reasoning and coding. E.g. '
					)),
					$(ae.$$.fragment),
					(Rn = i('.')),
					(nn = h()),
					(se = m('h3')),
					(se.textContent = zo),
					(on = h()),
					(le = m('p')),
					(jn = i('We’ve been using ”')),
					$(ie.$$.fragment),
					(Wn = i(
						'” to very accurately predict the size and speed of new computer systems for nearly 50 years. There are some arguments that the speed and size of computer chips might slow at some point in the future, but there has always been innovations to allow it to continue its exponential growth. With the next round of chips already being planned and/or produced, and the horizontal scalability of these AI systems, it is expected that LLMs will be able to perform at or near the level of a human brain in a matter of months or years!'
					)),
					(an = h()),
					(Qe = m('p')),
					(Qe.textContent = So),
					(sn = h()),
					(Ye = m('p')),
					(Ye.textContent = Bo),
					(ln = h()),
					(rt = m('blockquote')),
					(ft = m('p')),
					(Nn = i(
						'“I actually said that in 1999. I said that [AI] would match any person by 2029.” — Ray Kurzweil '
					)),
					$(re.$$.fragment),
					(rn = h()),
					(ut = m('blockquote')),
					(mt = m('p')),
					(Qn = i(
						'“If the rate of change continues, I think 2029, or maybe 2030, is where digital intelligence will probably exceed all human intelligence combined.” — Elon Musk '
					)),
					$(fe.$$.fragment),
					(fn = h()),
					(ue = m('h2')),
					(ue.textContent = Do),
					(un = h()),
					(Ve = m('p')),
					(Ve.innerHTML = Ko),
					(mn = h()),
					(M = m('p')),
					(Yn = i(
						'This uncontrollable intelligence feedback loop is often called FOOM, which stands for '
					)),
					(pt = m('em')),
					(pt.textContent = Ro),
					(Vn = i(`.
The possibility of FOOM is still `)),
					$(me.$$.fragment),
					(Xn = i(`.
But, the basic fundamental process can be argued as plausible, even when considered from first principles.`)),
					(pn = h()),
					(ht = m('blockquote')),
					(ct = m('p')),
					(Jn = i(
						'“AI systems do nearly all research and development, improvements in AI will accelerate the pace of technological progress, including further progress in AI. 26% responded likely in 2022. 17% responded likely in 2016” — '
					)),
					$(pe.$$.fragment),
					(hn = h()),
					(he = m('h2')),
					(he.textContent = jo),
					(cn = h()),
					(L = m('p')),
					(Zn =
						i(`When these digital brains become larger, or when they’re fed more data, they also get more unexpected capabilities.
It turns out to be very difficult to predict exactly what these capabilities will be.
This is why Google refers to them as `)),
					$(ce.$$.fragment),
					(eo = i(`.
For most capabilities, this is not a problem.
However, there are some `)),
					$(de.$$.fragment),
					(to = i(` (like hacking or bioweapon design) that we don’t want AI models to possess.
Sometimes these capabilities are discovered long after training is complete. For example, 18 months after GPT-4 finished training, researchers discovered that it can `)),
					$($e.$$.fragment),
					(no = i('.')),
					(dn = h()),
					(ge = m('blockquote')),
					(dt = m('p')),
					(dt.textContent = Wo),
					(oo = h()),
					(Ct = m('ul')),
					($t = m('li')),
					$(_e.$$.fragment),
					(ao = i('.')),
					($n = h()),
					(be = m('h2')),
					(be.textContent = No),
					(gn = h()),
					(Xe = m('p')),
					(Xe.innerHTML = Qo),
					(_n = h()),
					(H = m('ul')),
					(q = m('li')),
					(so = i(
						'A bug in GPT-2 resulted in an AI that did the exact opposite of what it was meant to do. It created '
					)),
					$(we.$$.fragment),
					(lo = i('. ')),
					$(ve.$$.fragment),
					(io = i(
						' explains how this happened and why it’s a problem. Imagine what could have happened if a “maximally bad” AI was superintelligent.'
					)),
					(ro = h()),
					(ye = m('li')),
					(fo = i(
						'For reasons still unknown, Microsoft’s Copilot (powered by GPT-4) went haywire in February 2024, threatening users: '
					)),
					$(xe.$$.fragment),
					(uo = h()),
					$(ke.$$.fragment),
					(mo = h()),
					(Je = m('li')),
					(po = i(
						'Every single large language model so far has been jailbroken - which means that with the right prompt, it would do things that its creators did not intend. For example, ChatGPT won’t give you the instructions on how to make napalm, but '
					)),
					$(Ie.$$.fragment),
					(ho = i('.')),
					(bn = h()),
					(Ce = m('p')),
					(co = i(
						'Even OpenAI does not expect this approach to scale up as their digital brains become smarter - it '
					)),
					$(Ae.$$.fragment),
					($o = i('.')),
					(wn = h()),
					(Le = m('blockquote')),
					(gt = m('p')),
					(gt.textContent = Yo),
					(go = h()),
					(At = m('ul')),
					(Lt = m('li')),
					$(Te.$$.fragment),
					(vn = h()),
					(Ee = m('h2')),
					(Ee.textContent = Vo),
					(yn = h()),
					(_t = m('blockquote')),
					(bt = m('p')),
					(_o = i(
						'“There are very few examples of a more intelligent thing being controlled by a less intelligent thing” - '
					)),
					$(Pe.$$.fragment),
					(xn = h()),
					(Ge = m('blockquote')),
					(wt = m('p')),
					(wt.textContent = Xo),
					(bo = h()),
					(Tt = m('ul')),
					(Et = m('li')),
					$(Me.$$.fragment),
					(kn = h()),
					(O = m('p')),
					(wo = i(
						'As we make these digital brains bigger and more powerful, they could become harder to control. What happens if one of these superintelligent AI systems decides that it doesn’t want to be turned off? This isn’t some fantasy problem - 86% of AI researchers believe that the control problem is '
					)),
					$(He.$$.fragment),
					(vo = i(`.
If we cannot control future AI systems, it could be `)),
					$(Oe.$$.fragment),
					(yo = i('.')),
					(In = h()),
					(qe = m('p')),
					(xo = i('But, there are various ')),
					$(Fe.$$.fragment),
					(ko = i(' that we can take to stop this!')),
					(Cn = h()),
					(Ue = m('p')),
					(Io = i('Let’s work together to ')),
					$(ze.$$.fragment),
					(Co = i('!')),
					this.h()
			},
			l(e) {
				;(n = p(e, 'P', { 'data-svelte-h': !0 })),
					x(n) !== 'svelte-v8rofc' && (n.innerHTML = t),
					(l = c(e)),
					(I = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(I) !== 'svelte-k8ki6m' && (I.textContent = k),
					(C = c(e)),
					(P = p(e, 'P', { 'data-svelte-h': !0 })),
					x(P) !== 'svelte-sqt2f0' && (P.textContent = Lo),
					(St = c(e)),
					(Be = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Be) !== 'svelte-em191o' && (Be.innerHTML = To),
					(Bt = c(e)),
					(K = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(K) !== 'svelte-6wgy3x' && (K.textContent = Eo),
					(Dt = c(e)),
					(De = p(e, 'P', { 'data-svelte-h': !0 })),
					x(De) !== 'svelte-fvssbk' && (De.textContent = Po),
					(Kt = c(e)),
					(Ke = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Ke) !== 'svelte-5ig298' && (Ke.textContent = Go),
					(Rt = c(e)),
					(Re = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Re) !== 'svelte-11oy5x9' && (Re.innerHTML = Mo),
					(jt = c(e)),
					(R = p(e, 'H3', { id: !0, 'data-svelte-h': !0 })),
					x(R) !== 'svelte-1sur6i0' && (R.textContent = Ho),
					(Wt = c(e)),
					(j = p(e, 'P', {}))
				var o = d(j)
				;(En = r(o, 'Human brains are estimated to have around ')),
					g(W.$$.fragment, o),
					(Pn = r(o, '.')),
					o.forEach(a),
					(Nt = c(e)),
					(N = p(e, 'P', {}))
				var Ze = d(N)
				;(Gn = r(
					Ze,
					'Current “frontier” AI powered LLMs (e.g. GPT4, Claude3, Gemini, etc.) have '
				)),
					g(Q.$$.fragment, Ze),
					(Mn = r(
						Ze,
						'. These “parameters” are thought to be some what analogous to “synapses” in the human brain.  So, GPT4-sized models are expected to be 1% the size of a human brain.'
					)),
					Ze.forEach(a),
					(Qt = c(e)),
					(je = p(e, 'P', { 'data-svelte-h': !0 })),
					x(je) !== 'svelte-1sqfiad' && (je.textContent = Oo),
					(Yt = c(e)),
					(Y = p(e, 'P', {}))
				var et = d(Y)
				;(Hn = r(
					et,
					'Rather than being trained with visual, audio and other sensory inputs, like human brains, the current LLMs are trained exclusively using nearly all the quality books and text that are available on the internet. This amount of text would take '
				)),
					g(V.$$.fragment, et),
					(On = r(et, '.')),
					et.forEach(a),
					(Vt = c(e)),
					(We = p(e, 'P', { 'data-svelte-h': !0 })),
					x(We) !== 'svelte-1tdb6vt' && (We.textContent = qo),
					(Xt = c(e)),
					(X = p(e, 'H3', { id: !0, 'data-svelte-h': !0 })),
					x(X) !== 'svelte-r2gvba' && (X.textContent = Fo),
					(Jt = c(e)),
					(J = p(e, 'P', {}))
				var tt = d(J)
				;(qn = r(tt, 'It is estimated that a human brain can perform between ')),
					g(Z.$$.fragment, tt),
					(Fn = r(
						tt,
						' (which is 10^18 or 1,000,000,000,000,000,000 floating point operations per second).'
					)),
					tt.forEach(a),
					(Zt = c(e)),
					(G = p(e, 'P', {}))
				var F = d(G)
				;(Un = r(
					F,
					'Current “frontier” AI powered LLMs are generally “run” on hundreds or thousands of current generation GPUs. (e.g. Nvidia A100s, H100s, etc.). And, Nvidia just recently announced their latest “next generation” GPU “server racks”, the '
				)),
					g(ee.$$.fragment, F),
					(zn = r(
						F,
						`.
One single instance/rack of this system is reported to be able to perform 1.44 ExaFlops of AI “Inference”.
So, one single `
					)),
					g(te.$$.fragment, F),
					(Sn = r(
						F,
						' maybe able to perform a similar number of operations/second as a single human brain.'
					)),
					F.forEach(a),
					(en = c(e)),
					(Ne = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Ne) !== 'svelte-1xrhx2d' && (Ne.textContent = Uo),
					(tn = c(e)),
					(A = p(e, 'P', {}))
				var T = d(A)
				;(Bn = r(T, 'On top of more traditional ')),
					g(ne.$$.fragment, T),
					(Dn = r(T, ' and ')),
					g(oe.$$.fragment, T),
					(Kn = r(
						T,
						' architectures, there has also been breakthroughs with other types of custom hardware that can greatly increase the speed of LLM “inference”, which is the process that an AI based LLM uses to do language processing, reasoning and coding. E.g. '
					)),
					g(ae.$$.fragment, T),
					(Rn = r(T, '.')),
					T.forEach(a),
					(nn = c(e)),
					(se = p(e, 'H3', { id: !0, 'data-svelte-h': !0 })),
					x(se) !== 'svelte-16zvcpr' && (se.textContent = zo),
					(on = c(e)),
					(le = p(e, 'P', {}))
				var nt = d(le)
				;(jn = r(nt, 'We’ve been using ”')),
					g(ie.$$.fragment, nt),
					(Wn = r(
						nt,
						'” to very accurately predict the size and speed of new computer systems for nearly 50 years. There are some arguments that the speed and size of computer chips might slow at some point in the future, but there has always been innovations to allow it to continue its exponential growth. With the next round of chips already being planned and/or produced, and the horizontal scalability of these AI systems, it is expected that LLMs will be able to perform at or near the level of a human brain in a matter of months or years!'
					)),
					nt.forEach(a),
					(an = c(e)),
					(Qe = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Qe) !== 'svelte-7juuh4' && (Qe.textContent = So),
					(sn = c(e)),
					(Ye = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Ye) !== 'svelte-1rdvlcb' && (Ye.textContent = Bo),
					(ln = c(e)),
					(rt = p(e, 'BLOCKQUOTE', {}))
				var Pt = d(rt)
				ft = p(Pt, 'P', {})
				var vt = d(ft)
				;(Nn = r(
					vt,
					'“I actually said that in 1999. I said that [AI] would match any person by 2029.” — Ray Kurzweil '
				)),
					g(re.$$.fragment, vt),
					vt.forEach(a),
					Pt.forEach(a),
					(rn = c(e)),
					(ut = p(e, 'BLOCKQUOTE', {}))
				var Gt = d(ut)
				mt = p(Gt, 'P', {})
				var yt = d(mt)
				;(Qn = r(
					yt,
					'“If the rate of change continues, I think 2029, or maybe 2030, is where digital intelligence will probably exceed all human intelligence combined.” — Elon Musk '
				)),
					g(fe.$$.fragment, yt),
					yt.forEach(a),
					Gt.forEach(a),
					(fn = c(e)),
					(ue = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(ue) !== 'svelte-1rzqb23' && (ue.textContent = Do),
					(un = c(e)),
					(Ve = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Ve) !== 'svelte-1hltw6y' && (Ve.innerHTML = Ko),
					(mn = c(e)),
					(M = p(e, 'P', {}))
				var U = d(M)
				;(Yn = r(
					U,
					'This uncontrollable intelligence feedback loop is often called FOOM, which stands for '
				)),
					(pt = p(U, 'EM', { 'data-svelte-h': !0 })),
					x(pt) !== 'svelte-wq0vvh' && (pt.textContent = Ro),
					(Vn = r(
						U,
						`.
The possibility of FOOM is still `
					)),
					g(me.$$.fragment, U),
					(Xn = r(
						U,
						`.
But, the basic fundamental process can be argued as plausible, even when considered from first principles.`
					)),
					U.forEach(a),
					(pn = c(e)),
					(ht = p(e, 'BLOCKQUOTE', {}))
				var Mt = d(ht)
				ct = p(Mt, 'P', {})
				var xt = d(ct)
				;(Jn = r(
					xt,
					'“AI systems do nearly all research and development, improvements in AI will accelerate the pace of technological progress, including further progress in AI. 26% responded likely in 2022. 17% responded likely in 2016” — '
				)),
					g(pe.$$.fragment, xt),
					xt.forEach(a),
					Mt.forEach(a),
					(hn = c(e)),
					(he = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(he) !== 'svelte-1mbij3f' && (he.textContent = jo),
					(cn = c(e)),
					(L = p(e, 'P', {}))
				var E = d(L)
				;(Zn = r(
					E,
					`When these digital brains become larger, or when they’re fed more data, they also get more unexpected capabilities.
It turns out to be very difficult to predict exactly what these capabilities will be.
This is why Google refers to them as `
				)),
					g(ce.$$.fragment, E),
					(eo = r(
						E,
						`.
For most capabilities, this is not a problem.
However, there are some `
					)),
					g(de.$$.fragment, E),
					(to = r(
						E,
						` (like hacking or bioweapon design) that we don’t want AI models to possess.
Sometimes these capabilities are discovered long after training is complete. For example, 18 months after GPT-4 finished training, researchers discovered that it can `
					)),
					g($e.$$.fragment, E),
					(no = r(E, '.')),
					E.forEach(a),
					(dn = c(e)),
					(ge = p(e, 'BLOCKQUOTE', {}))
				var ot = d(ge)
				;(dt = p(ot, 'P', { 'data-svelte-h': !0 })),
					x(dt) !== 'svelte-ket85a' && (dt.textContent = Wo),
					(oo = c(ot)),
					(Ct = p(ot, 'UL', {}))
				var Ht = d(Ct)
				$t = p(Ht, 'LI', {})
				var kt = d($t)
				g(_e.$$.fragment, kt),
					(ao = r(kt, '.')),
					kt.forEach(a),
					Ht.forEach(a),
					ot.forEach(a),
					($n = c(e)),
					(be = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(be) !== 'svelte-bklzgt' && (be.textContent = No),
					(gn = c(e)),
					(Xe = p(e, 'P', { 'data-svelte-h': !0 })),
					x(Xe) !== 'svelte-h9t4lu' && (Xe.innerHTML = Qo),
					(_n = c(e)),
					(H = p(e, 'UL', {}))
				var z = d(H)
				q = p(z, 'LI', {})
				var S = d(q)
				;(so = r(
					S,
					'A bug in GPT-2 resulted in an AI that did the exact opposite of what it was meant to do. It created '
				)),
					g(we.$$.fragment, S),
					(lo = r(S, '. ')),
					g(ve.$$.fragment, S),
					(io = r(
						S,
						' explains how this happened and why it’s a problem. Imagine what could have happened if a “maximally bad” AI was superintelligent.'
					)),
					S.forEach(a),
					(ro = c(z)),
					(ye = p(z, 'LI', {}))
				var Se = d(ye)
				;(fo = r(
					Se,
					'For reasons still unknown, Microsoft’s Copilot (powered by GPT-4) went haywire in February 2024, threatening users: '
				)),
					g(xe.$$.fragment, Se),
					(uo = c(Se)),
					g(ke.$$.fragment, Se),
					Se.forEach(a),
					(mo = c(z)),
					(Je = p(z, 'LI', {}))
				var at = d(Je)
				;(po = r(
					at,
					'Every single large language model so far has been jailbroken - which means that with the right prompt, it would do things that its creators did not intend. For example, ChatGPT won’t give you the instructions on how to make napalm, but '
				)),
					g(Ie.$$.fragment, at),
					(ho = r(at, '.')),
					at.forEach(a),
					z.forEach(a),
					(bn = c(e)),
					(Ce = p(e, 'P', {}))
				var st = d(Ce)
				;(co = r(
					st,
					'Even OpenAI does not expect this approach to scale up as their digital brains become smarter - it '
				)),
					g(Ae.$$.fragment, st),
					($o = r(st, '.')),
					st.forEach(a),
					(wn = c(e)),
					(Le = p(e, 'BLOCKQUOTE', {}))
				var lt = d(Le)
				;(gt = p(lt, 'P', { 'data-svelte-h': !0 })),
					x(gt) !== 'svelte-etl6b2' && (gt.textContent = Yo),
					(go = c(lt)),
					(At = p(lt, 'UL', {}))
				var Ot = d(At)
				Lt = p(Ot, 'LI', {})
				var qt = d(Lt)
				g(Te.$$.fragment, qt),
					qt.forEach(a),
					Ot.forEach(a),
					lt.forEach(a),
					(vn = c(e)),
					(Ee = p(e, 'H2', { id: !0, 'data-svelte-h': !0 })),
					x(Ee) !== 'svelte-yy57gf' && (Ee.textContent = Vo),
					(yn = c(e)),
					(_t = p(e, 'BLOCKQUOTE', {}))
				var Ft = d(_t)
				bt = p(Ft, 'P', {})
				var It = d(bt)
				;(_o = r(
					It,
					'“There are very few examples of a more intelligent thing being controlled by a less intelligent thing” - '
				)),
					g(Pe.$$.fragment, It),
					It.forEach(a),
					Ft.forEach(a),
					(xn = c(e)),
					(Ge = p(e, 'BLOCKQUOTE', {}))
				var it = d(Ge)
				;(wt = p(it, 'P', { 'data-svelte-h': !0 })),
					x(wt) !== 'svelte-1j6nkyf' && (wt.textContent = Xo),
					(bo = c(it)),
					(Tt = p(it, 'UL', {}))
				var Ut = d(Tt)
				Et = p(Ut, 'LI', {})
				var zt = d(Et)
				g(Me.$$.fragment, zt),
					zt.forEach(a),
					Ut.forEach(a),
					it.forEach(a),
					(kn = c(e)),
					(O = p(e, 'P', {}))
				var B = d(O)
				;(wo = r(
					B,
					'As we make these digital brains bigger and more powerful, they could become harder to control. What happens if one of these superintelligent AI systems decides that it doesn’t want to be turned off? This isn’t some fantasy problem - 86% of AI researchers believe that the control problem is '
				)),
					g(He.$$.fragment, B),
					(vo = r(
						B,
						`.
If we cannot control future AI systems, it could be `
					)),
					g(Oe.$$.fragment, B),
					(yo = r(B, '.')),
					B.forEach(a),
					(In = c(e)),
					(qe = p(e, 'P', {}))
				var Ln = d(qe)
				;(xo = r(Ln, 'But, there are various ')),
					g(Fe.$$.fragment, Ln),
					(ko = r(Ln, ' that we can take to stop this!')),
					Ln.forEach(a),
					(Cn = c(e)),
					(Ue = p(e, 'P', {}))
				var Tn = d(Ue)
				;(Io = r(Tn, 'Let’s work together to ')),
					g(ze.$$.fragment, Tn),
					(Co = r(Tn, '!')),
					Tn.forEach(a),
					this.h()
			},
			h() {
				D(I, 'id', 'modern-ai-models-are-grown-not-programmed'),
					D(K, 'id', 'digital-vs-human-brains-how-close-are-we-really'),
					D(R, 'id', 'size'),
					D(X, 'id', 'speed'),
					D(se, 'id', 'exponential-growth'),
					D(ue, 'id', 'uncontrollable-scaling'),
					D(he, 'id', 'unpredictable-scaling'),
					D(be, 'id', 'unpredictable-behavior'),
					D(Ee, 'id', 'uncontrollable-ai')
			},
			m(e, o) {
				s(e, n, o),
					s(e, l, o),
					s(e, I, o),
					s(e, C, o),
					s(e, P, o),
					s(e, St, o),
					s(e, Be, o),
					s(e, Bt, o),
					s(e, K, o),
					s(e, Dt, o),
					s(e, De, o),
					s(e, Kt, o),
					s(e, Ke, o),
					s(e, Rt, o),
					s(e, Re, o),
					s(e, jt, o),
					s(e, R, o),
					s(e, Wt, o),
					s(e, j, o),
					u(j, En),
					_(W, j, null),
					u(j, Pn),
					s(e, Nt, o),
					s(e, N, o),
					u(N, Gn),
					_(Q, N, null),
					u(N, Mn),
					s(e, Qt, o),
					s(e, je, o),
					s(e, Yt, o),
					s(e, Y, o),
					u(Y, Hn),
					_(V, Y, null),
					u(Y, On),
					s(e, Vt, o),
					s(e, We, o),
					s(e, Xt, o),
					s(e, X, o),
					s(e, Jt, o),
					s(e, J, o),
					u(J, qn),
					_(Z, J, null),
					u(J, Fn),
					s(e, Zt, o),
					s(e, G, o),
					u(G, Un),
					_(ee, G, null),
					u(G, zn),
					_(te, G, null),
					u(G, Sn),
					s(e, en, o),
					s(e, Ne, o),
					s(e, tn, o),
					s(e, A, o),
					u(A, Bn),
					_(ne, A, null),
					u(A, Dn),
					_(oe, A, null),
					u(A, Kn),
					_(ae, A, null),
					u(A, Rn),
					s(e, nn, o),
					s(e, se, o),
					s(e, on, o),
					s(e, le, o),
					u(le, jn),
					_(ie, le, null),
					u(le, Wn),
					s(e, an, o),
					s(e, Qe, o),
					s(e, sn, o),
					s(e, Ye, o),
					s(e, ln, o),
					s(e, rt, o),
					u(rt, ft),
					u(ft, Nn),
					_(re, ft, null),
					s(e, rn, o),
					s(e, ut, o),
					u(ut, mt),
					u(mt, Qn),
					_(fe, mt, null),
					s(e, fn, o),
					s(e, ue, o),
					s(e, un, o),
					s(e, Ve, o),
					s(e, mn, o),
					s(e, M, o),
					u(M, Yn),
					u(M, pt),
					u(M, Vn),
					_(me, M, null),
					u(M, Xn),
					s(e, pn, o),
					s(e, ht, o),
					u(ht, ct),
					u(ct, Jn),
					_(pe, ct, null),
					s(e, hn, o),
					s(e, he, o),
					s(e, cn, o),
					s(e, L, o),
					u(L, Zn),
					_(ce, L, null),
					u(L, eo),
					_(de, L, null),
					u(L, to),
					_($e, L, null),
					u(L, no),
					s(e, dn, o),
					s(e, ge, o),
					u(ge, dt),
					u(ge, oo),
					u(ge, Ct),
					u(Ct, $t),
					_(_e, $t, null),
					u($t, ao),
					s(e, $n, o),
					s(e, be, o),
					s(e, gn, o),
					s(e, Xe, o),
					s(e, _n, o),
					s(e, H, o),
					u(H, q),
					u(q, so),
					_(we, q, null),
					u(q, lo),
					_(ve, q, null),
					u(q, io),
					u(H, ro),
					u(H, ye),
					u(ye, fo),
					_(xe, ye, null),
					u(ye, uo),
					_(ke, ye, null),
					u(H, mo),
					u(H, Je),
					u(Je, po),
					_(Ie, Je, null),
					u(Je, ho),
					s(e, bn, o),
					s(e, Ce, o),
					u(Ce, co),
					_(Ae, Ce, null),
					u(Ce, $o),
					s(e, wn, o),
					s(e, Le, o),
					u(Le, gt),
					u(Le, go),
					u(Le, At),
					u(At, Lt),
					_(Te, Lt, null),
					s(e, vn, o),
					s(e, Ee, o),
					s(e, yn, o),
					s(e, _t, o),
					u(_t, bt),
					u(bt, _o),
					_(Pe, bt, null),
					s(e, xn, o),
					s(e, Ge, o),
					u(Ge, wt),
					u(Ge, bo),
					u(Ge, Tt),
					u(Tt, Et),
					_(Me, Et, null),
					s(e, kn, o),
					s(e, O, o),
					u(O, wo),
					_(He, O, null),
					u(O, vo),
					_(Oe, O, null),
					u(O, yo),
					s(e, In, o),
					s(e, qe, o),
					u(qe, xo),
					_(Fe, qe, null),
					u(qe, ko),
					s(e, Cn, o),
					s(e, Ue, o),
					u(Ue, Io),
					_(ze, Ue, null),
					u(Ue, Co),
					(An = !0)
			},
			p(e, o) {
				const Ze = {}
				o & 2 && (Ze.$$scope = { dirty: o, ctx: e }), W.$set(Ze)
				const et = {}
				o & 2 && (et.$$scope = { dirty: o, ctx: e }), Q.$set(et)
				const tt = {}
				o & 2 && (tt.$$scope = { dirty: o, ctx: e }), V.$set(tt)
				const F = {}
				o & 2 && (F.$$scope = { dirty: o, ctx: e }), Z.$set(F)
				const T = {}
				o & 2 && (T.$$scope = { dirty: o, ctx: e }), ee.$set(T)
				const nt = {}
				o & 2 && (nt.$$scope = { dirty: o, ctx: e }), te.$set(nt)
				const Pt = {}
				o & 2 && (Pt.$$scope = { dirty: o, ctx: e }), ne.$set(Pt)
				const vt = {}
				o & 2 && (vt.$$scope = { dirty: o, ctx: e }), oe.$set(vt)
				const Gt = {}
				o & 2 && (Gt.$$scope = { dirty: o, ctx: e }), ae.$set(Gt)
				const yt = {}
				o & 2 && (yt.$$scope = { dirty: o, ctx: e }), ie.$set(yt)
				const U = {}
				o & 2 && (U.$$scope = { dirty: o, ctx: e }), re.$set(U)
				const Mt = {}
				o & 2 && (Mt.$$scope = { dirty: o, ctx: e }), fe.$set(Mt)
				const xt = {}
				o & 2 && (xt.$$scope = { dirty: o, ctx: e }), me.$set(xt)
				const E = {}
				o & 2 && (E.$$scope = { dirty: o, ctx: e }), pe.$set(E)
				const ot = {}
				o & 2 && (ot.$$scope = { dirty: o, ctx: e }), ce.$set(ot)
				const Ht = {}
				o & 2 && (Ht.$$scope = { dirty: o, ctx: e }), de.$set(Ht)
				const kt = {}
				o & 2 && (kt.$$scope = { dirty: o, ctx: e }), $e.$set(kt)
				const z = {}
				o & 2 && (z.$$scope = { dirty: o, ctx: e }), _e.$set(z)
				const S = {}
				o & 2 && (S.$$scope = { dirty: o, ctx: e }), we.$set(S)
				const Se = {}
				o & 2 && (Se.$$scope = { dirty: o, ctx: e }), ve.$set(Se)
				const at = {}
				o & 2 && (at.$$scope = { dirty: o, ctx: e }), xe.$set(at)
				const st = {}
				o & 2 && (st.$$scope = { dirty: o, ctx: e }), ke.$set(st)
				const lt = {}
				o & 2 && (lt.$$scope = { dirty: o, ctx: e }), Ie.$set(lt)
				const Ot = {}
				o & 2 && (Ot.$$scope = { dirty: o, ctx: e }), Ae.$set(Ot)
				const qt = {}
				o & 2 && (qt.$$scope = { dirty: o, ctx: e }), Te.$set(qt)
				const Ft = {}
				o & 2 && (Ft.$$scope = { dirty: o, ctx: e }), Pe.$set(Ft)
				const It = {}
				o & 2 && (It.$$scope = { dirty: o, ctx: e }), Me.$set(It)
				const it = {}
				o & 2 && (it.$$scope = { dirty: o, ctx: e }), He.$set(it)
				const Ut = {}
				o & 2 && (Ut.$$scope = { dirty: o, ctx: e }), Oe.$set(Ut)
				const zt = {}
				o & 2 && (zt.$$scope = { dirty: o, ctx: e }), Fe.$set(zt)
				const B = {}
				o & 2 && (B.$$scope = { dirty: o, ctx: e }), ze.$set(B)
			},
			i(e) {
				An ||
					(b(W.$$.fragment, e),
					b(Q.$$.fragment, e),
					b(V.$$.fragment, e),
					b(Z.$$.fragment, e),
					b(ee.$$.fragment, e),
					b(te.$$.fragment, e),
					b(ne.$$.fragment, e),
					b(oe.$$.fragment, e),
					b(ae.$$.fragment, e),
					b(ie.$$.fragment, e),
					b(re.$$.fragment, e),
					b(fe.$$.fragment, e),
					b(me.$$.fragment, e),
					b(pe.$$.fragment, e),
					b(ce.$$.fragment, e),
					b(de.$$.fragment, e),
					b($e.$$.fragment, e),
					b(_e.$$.fragment, e),
					b(we.$$.fragment, e),
					b(ve.$$.fragment, e),
					b(xe.$$.fragment, e),
					b(ke.$$.fragment, e),
					b(Ie.$$.fragment, e),
					b(Ae.$$.fragment, e),
					b(Te.$$.fragment, e),
					b(Pe.$$.fragment, e),
					b(Me.$$.fragment, e),
					b(He.$$.fragment, e),
					b(Oe.$$.fragment, e),
					b(Fe.$$.fragment, e),
					b(ze.$$.fragment, e),
					(An = !0))
			},
			o(e) {
				w(W.$$.fragment, e),
					w(Q.$$.fragment, e),
					w(V.$$.fragment, e),
					w(Z.$$.fragment, e),
					w(ee.$$.fragment, e),
					w(te.$$.fragment, e),
					w(ne.$$.fragment, e),
					w(oe.$$.fragment, e),
					w(ae.$$.fragment, e),
					w(ie.$$.fragment, e),
					w(re.$$.fragment, e),
					w(fe.$$.fragment, e),
					w(me.$$.fragment, e),
					w(pe.$$.fragment, e),
					w(ce.$$.fragment, e),
					w(de.$$.fragment, e),
					w($e.$$.fragment, e),
					w(_e.$$.fragment, e),
					w(we.$$.fragment, e),
					w(ve.$$.fragment, e),
					w(xe.$$.fragment, e),
					w(ke.$$.fragment, e),
					w(Ie.$$.fragment, e),
					w(Ae.$$.fragment, e),
					w(Te.$$.fragment, e),
					w(Pe.$$.fragment, e),
					w(Me.$$.fragment, e),
					w(He.$$.fragment, e),
					w(Oe.$$.fragment, e),
					w(Fe.$$.fragment, e),
					w(ze.$$.fragment, e),
					(An = !1)
			},
			d(e) {
				e &&
					(a(n),
					a(l),
					a(I),
					a(C),
					a(P),
					a(St),
					a(Be),
					a(Bt),
					a(K),
					a(Dt),
					a(De),
					a(Kt),
					a(Ke),
					a(Rt),
					a(Re),
					a(jt),
					a(R),
					a(Wt),
					a(j),
					a(Nt),
					a(N),
					a(Qt),
					a(je),
					a(Yt),
					a(Y),
					a(Vt),
					a(We),
					a(Xt),
					a(X),
					a(Jt),
					a(J),
					a(Zt),
					a(G),
					a(en),
					a(Ne),
					a(tn),
					a(A),
					a(nn),
					a(se),
					a(on),
					a(le),
					a(an),
					a(Qe),
					a(sn),
					a(Ye),
					a(ln),
					a(rt),
					a(rn),
					a(ut),
					a(fn),
					a(ue),
					a(un),
					a(Ve),
					a(mn),
					a(M),
					a(pn),
					a(ht),
					a(hn),
					a(he),
					a(cn),
					a(L),
					a(dn),
					a(ge),
					a($n),
					a(be),
					a(gn),
					a(Xe),
					a(_n),
					a(H),
					a(bn),
					a(Ce),
					a(wn),
					a(Le),
					a(vn),
					a(Ee),
					a(yn),
					a(_t),
					a(xn),
					a(Ge),
					a(kn),
					a(O),
					a(In),
					a(qe),
					a(Cn),
					a(Ue)),
					v(W),
					v(Q),
					v(V),
					v(Z),
					v(ee),
					v(te),
					v(ne),
					v(oe),
					v(ae),
					v(ie),
					v(re),
					v(fe),
					v(me),
					v(pe),
					v(ce),
					v(de),
					v($e),
					v(_e),
					v(we),
					v(ve),
					v(xe),
					v(ke),
					v(Ie),
					v(Ae),
					v(Te),
					v(Pe),
					v(Me),
					v(He),
					v(Oe),
					v(Fe),
					v(ze)
			}
		}
	)
}
function za(f) {
	let n, t
	const l = [f[0], ea]
	let I = { $$slots: { default: [Ua] }, $$scope: { ctx: f } }
	for (let k = 0; k < l.length; k += 1) I = Ao(I, l[k])
	return (
		(n = new la({ props: I })),
		{
			c() {
				$(n.$$.fragment)
			},
			l(k) {
				g(n.$$.fragment, k)
			},
			m(k, C) {
				_(n, k, C), (t = !0)
			},
			p(k, [C]) {
				const P = C & 1 ? sa(l, [C & 1 && Zo(k[0]), C & 0 && Zo(ea)]) : {}
				C & 2 && (P.$$scope = { dirty: C, ctx: k }), n.$set(P)
			},
			i(k) {
				t || (b(n.$$.fragment, k), (t = !0))
			},
			o(k) {
				w(n.$$.fragment, k), (t = !1)
			},
			d(k) {
				v(n, k)
			}
		}
	)
}
const ea = {
	title: 'AI models are unpredictable digital brains',
	description:
		'Nobody understands how AI models work, nobody can predict their behavior, and nobody will be able to control them.'
}
function Sa(f, n, t) {
	return (
		(f.$$set = (l) => {
			t(0, (n = Ao(Ao({}, n), Jo(l))))
		}),
		(n = Jo(n)),
		[n]
	)
}
class Wa extends oa {
	constructor(n) {
		super(), aa(this, n, Sa, za, ta, {})
	}
}
export { Wa as default, ea as metadata }
